{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "829ecfe7",
   "metadata": {},
   "source": [
    "# 1. Combinar archivos \n",
    "#### Archivo de enrgia extraida con archivo de empresas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c42c2440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:112: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:112: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\4005102116.py:112: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df = df[~df['CENTRAL'].str.upper().str.contains('CENTRAL\\s*ENERGIA|POTENCIA', na=False)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Iniciando procesamiento de archivos...\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0123.xlsx ‚Üí ./downloads/ingresos_centrales_0123.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0124.xlsx ‚Üí ./downloads/ingresos_centrales_0124.xlsx\n",
      "  ‚ö†Ô∏è 1 centrales sin GENERADOR: ['Yunchar√°']\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0125.xlsx ‚Üí ./downloads/ingresos_centrales_0125.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0223.xlsx ‚Üí ./downloads/ingresos_centrales_0223.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0224.xlsx ‚Üí ./downloads/ingresos_centrales_0224.xlsx\n",
      "  ‚ö†Ô∏è 1 centrales sin GENERADOR: ['Yunchar√°']\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0225.xlsx ‚Üí ./downloads/ingresos_centrales_0225.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0323.xlsx ‚Üí ./downloads/ingresos_centrales_0323.xlsx\n",
      "  ‚ö†Ô∏è 5 centrales sin GENERADOR: ['San Borja' 'Rurrenabaque' 'Yucumo']...\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0324.xlsx ‚Üí ./downloads/ingresos_centrales_0324.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0325.xlsx ‚Üí ./downloads/ingresos_centrales_0325.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0423.xlsx ‚Üí ./downloads/ingresos_centrales_0423.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0424.xlsx ‚Üí ./downloads/ingresos_centrales_0424.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0425.xlsx ‚Üí ./downloads/ingresos_centrales_0425.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0523.xlsx ‚Üí ./downloads/ingresos_centrales_0523.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0524.xlsx ‚Üí ./downloads/ingresos_centrales_0524.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0525.xlsx ‚Üí ./downloads/ingresos_centrales_0525.xlsx\n",
      "  ‚ö†Ô∏è 1 centrales sin GENERADOR: ['Uyuni (Fase II)']\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0623.xlsx ‚Üí ./downloads/ingresos_centrales_0623.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0624.xlsx ‚Üí ./downloads/ingresos_centrales_0624.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0625.xlsx ‚Üí ./downloads/ingresos_centrales_0625.xlsx\n",
      "  ‚ö†Ô∏è 1 centrales sin GENERADOR: ['Uyuni (Fase II)']\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0723.xlsx ‚Üí ./downloads/ingresos_centrales_0723.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0724.xlsx ‚Üí ./downloads/ingresos_centrales_0724.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0823.xlsx ‚Üí ./downloads/ingresos_centrales_0823.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0824.xlsx ‚Üí ./downloads/ingresos_centrales_0824.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0923.xlsx ‚Üí ./downloads/ingresos_centrales_0923.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_0924.xlsx ‚Üí ./downloads/ingresos_centrales_0924.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_1023.xlsx ‚Üí ./downloads/ingresos_centrales_1023.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_1024.xlsx ‚Üí ./downloads/ingresos_centrales_1024.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_1123.xlsx ‚Üí ./downloads/ingresos_centrales_1123.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_1124.xlsx ‚Üí ./downloads/ingresos_centrales_1124.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_1223.xlsx ‚Üí ./downloads/ingresos_centrales_1223.xlsx\n",
      "[OK] ./downloads\\extracted_ingresos_c_iny_1224.xlsx ‚Üí ./downloads/ingresos_centrales_1224.xlsx\n",
      "‚úÖ Proceso completado.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIGURACI√ìN ===\n",
    "CENTRALES_FILE = './data/1_empresas.xlsx'\n",
    "INPUT_PATTERN = './downloads/extracted_ingresos_c_iny_*.xlsx'\n",
    "OUTPUT_PREFIX = './downloads/ingresos_centrales_'\n",
    "\n",
    "# === FUNCIONES AUXILIARES ===\n",
    "\n",
    "def detectar_fila_encabezado(df):\n",
    "    for i, row in df.iterrows():\n",
    "        if any(str(cell).strip().upper() == \"CENTRAL\" for cell in row):\n",
    "            return i\n",
    "    return 0\n",
    "\n",
    "def normalizar_nombre(nombre, nombres_centrales, alias):\n",
    "    x = str(nombre).strip()\n",
    "    if x in alias:\n",
    "        return alias[x]\n",
    "    \n",
    "    # Limpieza m√°s profunda para coincidencias flexibles\n",
    "    x_clean = re.sub(r'\\W+', '', x).upper()\n",
    "    \n",
    "    for k in nombres_centrales:\n",
    "        k_clean = re.sub(r'\\W+', '', k).upper()\n",
    "        if k_clean == x_clean:\n",
    "            return k\n",
    "    \n",
    "    # Casos especiales para Agua√≠\n",
    "    if \"AGUAI\" in x_clean or \"AGUA√ç\" in x_clean:\n",
    "        if \"AUTOPRODUCTOR\" in x_clean:\n",
    "            return \"Aguai (Autoproductor)\"\n",
    "        return \"Agua√≠ Energia\"\n",
    "    \n",
    "    return x\n",
    "\n",
    "# === MAPA DE ALIAS DE CENTRALES ===\n",
    "alias = {\n",
    "    \"Kanata en Arocagua\": \"Kanata ARO\",\n",
    "    \"Kanata en Valle Hermoso\": \"Kanata VHE\",\n",
    "    \"Misicuni en Arocagua\": \"Misicuni ARO\",\n",
    "    \"Misicuni en Valle Hermoso\": \"Misicuni VHE\",\n",
    "    \"Yunchara\": \"Yunchara\",\n",
    "    \"Agua√≠ Energ√≠a\": \"Agua√≠ Energia\",\n",
    "    \"AGUA√ç ENERG√çA S.A.\": \"Agua√≠ Energia\",\n",
    "    \"Santa Cruz (Agua√≠)\": \"Santa Cruz (Agua√≠)\",\n",
    "    \"R√çO EL√âCTRICO S.A.\": \"RIO ELECTRICO S.A.\",\n",
    "    \"CHACO ENERG√çAS S.A.\": \"CHACO ENERGIAS S.A.\",\n",
    "    \"RIOELEC S.A.\": \"RIO ELECTRICO S.A.\",\n",
    "}\n",
    "\n",
    "# === PROCESAMIENTO DE ARCHIVOS ===\n",
    "\n",
    "def procesar_archivos():\n",
    "    try:\n",
    "        df_centrales = pd.read_excel(CENTRALES_FILE)\n",
    "        df_centrales['CENTRAL'] = df_centrales['CENTRAL'].astype(str).str.strip()\n",
    "\n",
    "        if not {'CENTRAL', 'GENERADOR', 'TECNOLOGIA'}.issubset(df_centrales.columns):\n",
    "            print(\"Error: El archivo debe contener columnas 'CENTRAL', 'GENERADOR' y 'TECNOLOGIA'\")\n",
    "            return\n",
    "\n",
    "        mapeo_generadores = dict(zip(df_centrales['CENTRAL'], df_centrales['GENERADOR']))\n",
    "        mapeo_tecnologia = dict(zip(df_centrales['CENTRAL'], df_centrales['TECNOLOGIA']))\n",
    "        nombres_centrales = set(df_centrales['CENTRAL'])\n",
    "\n",
    "        # Asegurar centrales de Agua√≠ en el mapeo\n",
    "        for central_aguai in [\"Agua√≠ Energia\", \"Aguai (Autoproductor)\"]:\n",
    "            if central_aguai not in mapeo_generadores:\n",
    "                mapeo_generadores[central_aguai] = \"AGUA√ç ENERG√çA S.A.\"\n",
    "                mapeo_tecnologia[central_aguai] = \"Biomasa\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar archivo de mapeo {CENTRALES_FILE}: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    for input_file in glob.glob(INPUT_PATTERN):\n",
    "        file_number = re.search(r'extracted_ingresos_c_iny_(\\d+)\\.xlsx', input_file)\n",
    "        if not file_number:\n",
    "            continue\n",
    "\n",
    "        file_number = file_number.group(1)\n",
    "        output_file = f\"{OUTPUT_PREFIX}{file_number}.xlsx\"\n",
    "\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"[Omitido] {output_file} ya existe.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df_raw = pd.read_excel(input_file, header=None)\n",
    "            start_row = detectar_fila_encabezado(df_raw)\n",
    "            df = pd.read_excel(input_file, skiprows=start_row)\n",
    "            df.columns = [str(col).strip() for col in df.columns]\n",
    "\n",
    "            central_col = next((c for c in df.columns if 'central' in c.lower() or 'agente' in c.lower()), None)\n",
    "            if central_col and central_col != 'CENTRAL':\n",
    "                df = df.rename(columns={central_col: 'CENTRAL'})\n",
    "            if 'CENTRAL' not in df.columns:\n",
    "                print(f\"[Error] No se encontr√≥ columna 'CENTRAL' en {input_file}\")\n",
    "                continue\n",
    "\n",
    "            df['CENTRAL'] = df['CENTRAL'].astype(str).str.strip()\n",
    "\n",
    "            # Eliminaci√≥n de filas basura (incluyendo totales de Agua√≠)\n",
    "            pattern_basura = r'TOTAL|TOTALES|Nota|Tipo de cambio|nan|CARGOS POR INYECCIONES|TOTAL\\s*-\\s*AGUAI'\n",
    "            df = df[~df['CENTRAL'].str.contains(pattern_basura, case=False, na=True, regex=True)]\n",
    "            df = df[~df['CENTRAL'].str.match(r'^\\d{4}-\\d{2}-\\d{2}', na=False)]\n",
    "            df = df[~df['CENTRAL'].str.upper().str.contains('CENTRAL\\s*ENERGIA|POTENCIA', na=False)]\n",
    "            df = df[df['CENTRAL'].notna() & (df['CENTRAL'] != '')]\n",
    "\n",
    "            # Identificaci√≥n de filas v√°lidas\n",
    "            df['CENTRAL_CLEAN'] = df['CENTRAL'].str.strip().str.upper()\n",
    "            centrales_validas = set(x.upper() for x in nombres_centrales)\n",
    "            first_valid_idx = df[df['CENTRAL_CLEAN'].isin(centrales_validas)].index.min()\n",
    "            if pd.isna(first_valid_idx):\n",
    "                print(f\"[Error] No se encontraron centrales v√°lidas en {input_file}\")\n",
    "                continue\n",
    "            df = df.loc[first_valid_idx:].copy()\n",
    "\n",
    "            # Normalizaci√≥n y mapeo\n",
    "            df['CENTRAL_NORMALIZADA'] = df['CENTRAL'].apply(\n",
    "                lambda x: normalizar_nombre(x, nombres_centrales, alias)\n",
    "            )\n",
    "            df['GENERADOR'] = df['CENTRAL_NORMALIZADA'].map(mapeo_generadores)\n",
    "            df['TECNOLOGIA'] = df['CENTRAL_NORMALIZADA'].map(mapeo_tecnologia)\n",
    "\n",
    "            # Forzar presencia de ambas centrales Agua√≠\n",
    "            aguai_centrales = [\"Agua√≠ Energia\", \"Aguai (Autoproductor)\"]\n",
    "            for central in aguai_centrales:\n",
    "                if central not in df['CENTRAL_NORMALIZADA'].values:\n",
    "                    nueva_fila = {\n",
    "                        'CENTRAL': central,\n",
    "                        'CENTRAL_NORMALIZADA': central,\n",
    "                        'GENERADOR': \"AGUA√ç ENERG√çA S.A.\",\n",
    "                        'TECNOLOGIA': \"Biomasa\"\n",
    "                    }\n",
    "                    for col in df.columns:\n",
    "                        if 'kW' in col or 'kWh' in col:\n",
    "                            nueva_fila[col] = 0.0\n",
    "                    df = pd.concat([df, pd.DataFrame([nueva_fila])], ignore_index=True)\n",
    "\n",
    "            # Procesamiento num√©rico\n",
    "            for col in df.columns:\n",
    "                if 'kW' in col or 'kWh' in col:\n",
    "                    df[col] = (\n",
    "                        df[col]\n",
    "                        .astype(str)\n",
    "                        .str.replace(',', '')\n",
    "                        .str.replace(' ', '')\n",
    "                        .replace('nan', None)\n",
    "                        .astype(float)\n",
    "                    )\n",
    "\n",
    "            # ... c√≥digo existente ...\n",
    "\n",
    "            columnas_finales = ['CENTRAL_NORMALIZADA', 'GENERADOR', 'TECNOLOGIA'] + [\n",
    "                c for c in df.columns if c not in ['CENTRAL', 'CENTRAL_NORMALIZADA', 'CENTRAL_CLEAN', 'GENERADOR', 'TECNOLOGIA']\n",
    "            ]\n",
    "            df_final = df[columnas_finales].rename(columns={'CENTRAL_NORMALIZADA': 'CENTRAL'})\n",
    "\n",
    "\n",
    "# ... resto del c√≥digo existente ...\n",
    "            # Guardar el DataFrame final\n",
    "            df_final.to_excel(output_file, index=False)\n",
    "\n",
    "            print(f\"[OK] {input_file} ‚Üí {output_file}\")\n",
    "\n",
    "            # Detectar centrales sin mapeo\n",
    "            faltantes = df_final[df_final['GENERADOR'].isna()]['CENTRAL'].unique()\n",
    "            if len(faltantes) > 0:\n",
    "                print(f\"  ‚ö†Ô∏è {len(faltantes)} centrales sin GENERADOR: {faltantes[:3]}{'...' if len(faltantes) > 3 else ''}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] {input_file}: {str(e)}\")\n",
    "            try:\n",
    "                Path('./errors').mkdir(exist_ok=True)\n",
    "                df.to_excel(f\"./errors/ERROR_{file_number}.xlsx\", index=False)\n",
    "            except Exception as inner_e:\n",
    "                print(f\"Error al guardar archivo de error: {inner_e}\")\n",
    "\n",
    "# === EJECUCI√ìN PRINCIPAL ===\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üîÑ Iniciando procesamiento de archivos...\")\n",
    "    procesar_archivos()\n",
    "    print(\"‚úÖ Proceso completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af1003e",
   "metadata": {},
   "source": [
    "# 2. Merge archivos energia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98c74589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidaci√≥n completada en formato largo.\n",
      "Filas totales: 5068\n",
      "Archivo guardado como 'serie_temporal_ingresos.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "def consolidar_en_formato_largo():\n",
    "    archivos = sorted(glob.glob('./downloads/ingresos_centrales_*.xlsx'))\n",
    "    if not archivos:\n",
    "        print(\"No se encontraron archivos.\")\n",
    "        return\n",
    "\n",
    "    registros = []\n",
    "\n",
    "    for archivo in archivos:\n",
    "        try:\n",
    "            # Extraer mes y a√±o del nombre del archivo\n",
    "            periodo = archivo.split('_')[-1].split('.')[0]\n",
    "            mes = int(periodo[:2])\n",
    "            a√±o = 2000 + int(periodo[2:])\n",
    "            fecha = datetime(a√±o, mes, 1)\n",
    "\n",
    "            df = pd.read_excel(archivo)\n",
    "\n",
    "            # Verificar columnas esenciales\n",
    "            if 'CENTRAL' not in df.columns:\n",
    "                print(f\"Omitido: {archivo} no tiene columna CENTRAL.\")\n",
    "                continue\n",
    "\n",
    "            columnas_necesarias = ['CENTRAL', 'GENERADOR']\n",
    "            columnas_datos = [col for col in df.columns if col not in columnas_necesarias + ['TECNOLOGIA']]\n",
    "            \n",
    "            # Si no hay columnas de datos, omitir\n",
    "            if not columnas_datos:\n",
    "                print(f\"Omitido: {archivo} no tiene columnas de datos.\")\n",
    "                continue\n",
    "\n",
    "            # Si no existe columna TECNOLOGIA, crear una con NaN\n",
    "            if 'TECNOLOGIA' not in df.columns:\n",
    "                df['TECNOLOGIA'] = None\n",
    "\n",
    "            # Derretir (melt) el DataFrame para convertir a formato largo\n",
    "            temp = pd.melt(\n",
    "                df,\n",
    "                id_vars=['CENTRAL', 'GENERADOR', 'TECNOLOGIA'],\n",
    "                value_vars=columnas_datos,\n",
    "                var_name='VARIABLE',\n",
    "                value_name='VALOR'\n",
    "            )\n",
    "            \n",
    "            temp['FECHA'] = fecha\n",
    "            registros.append(temp)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {archivo}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not registros:\n",
    "        print(\"No se pudo consolidar ning√∫n archivo v√°lido.\")\n",
    "        return\n",
    "\n",
    "    df_largo = pd.concat(registros, ignore_index=True)\n",
    "    df_largo = df_largo[['FECHA', 'CENTRAL', 'GENERADOR', 'TECNOLOGIA', 'VARIABLE', 'VALOR']]\n",
    "\n",
    "    df_largo.to_excel(\"./preprocess/serie_temporal_ingresos.xlsx\", index=False)\n",
    "    print(\"Consolidaci√≥n completada en formato largo.\")\n",
    "    print(f\"Filas totales: {len(df_largo)}\")\n",
    "    print(\"Archivo guardado como 'serie_temporal_ingresos.xlsx'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    consolidar_en_formato_largo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcaea20",
   "metadata": {},
   "source": [
    "# 3. Creacion de serie de tiempo de energia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d927312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\320038066.py:32: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['CENTRAL'] = df['CENTRAL'].replace('nan', pd.NA).fillna(method='ffill')\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\320038066.py:33: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['GENERADOR'] = df['GENERADOR'].replace('nan', pd.NA).fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leer archivo\n",
    "df = pd.read_excel(\"./preprocess/serie_temporal_ingresos.xlsx\")\n",
    "\n",
    "# Convertir FECHA y eliminar filas sin fecha v√°lida\n",
    "df['FECHA'] = pd.to_datetime(df['FECHA'], errors='coerce', unit='d')\n",
    "df = df.dropna(subset=['FECHA'])\n",
    "\n",
    "# Limpiar espacios en columnas clave\n",
    "df['CENTRAL'] = df['CENTRAL'].astype(str).str.strip()\n",
    "df['GENERADOR'] = df['GENERADOR'].astype(str).str.strip()\n",
    "df['TECNOLOGIA'] = df['TECNOLOGIA'].astype(str).str.strip()\n",
    "df['VARIABLE'] = df['VARIABLE'].astype(str).str.strip()\n",
    "\n",
    "# Filtrar s√≥lo las variables de inter√©s exactas (con may√∫sculas y espacios)\n",
    "df = df[df['VARIABLE'].isin([\n",
    "    \"Energ√≠a KWh\",\n",
    "    'Ingresos Energ√≠a USD',\n",
    "    'Ingresos Renovables USD',\n",
    "    'Ingresos Potencia USD'\n",
    "])]\n",
    "\n",
    "# Asegurar que VALOR sea num√©rico\n",
    "df['VALOR'] = pd.to_numeric(df['VALOR'], errors='coerce')\n",
    "df = df.dropna(subset=['VALOR'])\n",
    "\n",
    "# Crear MES_ANIO\n",
    "df['MES_ANIO'] = df['FECHA'].dt.strftime('%m%Y')\n",
    "\n",
    "# Reemplazar valores faltantes en AGENTE y EMPRESA con forward fill\n",
    "df['CENTRAL'] = df['CENTRAL'].replace('nan', pd.NA).fillna(method='ffill')\n",
    "df['GENERADOR'] = df['GENERADOR'].replace('nan', pd.NA).fillna(method='ffill')\n",
    "\n",
    "# Crear columna pivote combinando variable y mes_a√±o (con espacios y may√∫sculas)\n",
    "df['COLUMNA'] = df['VARIABLE'] + ' ' + df['MES_ANIO']\n",
    "\n",
    "# Pivotear el DataFrame\n",
    "df_pivot = df.pivot_table(index=['CENTRAL', 'GENERADOR', \"TECNOLOGIA\"], columns='COLUMNA', values='VALOR', aggfunc='first')\n",
    "\n",
    "# Funci√≥n para extraer a√±o y mes para ordenar correctamente\n",
    "def extraer_anio_mes(col_name):\n",
    "    try:\n",
    "        # Extraer la parte de la fecha (√∫ltimos 6 caracteres)\n",
    "        fecha = col_name.split()[-1]\n",
    "        mes = int(fecha[:2])\n",
    "        anio = int(fecha[2:])\n",
    "        return (anio, mes)\n",
    "    except:\n",
    "        return (0, 0)  # Para manejar posibles errores\n",
    "\n",
    "# Obtener lista de columnas\n",
    "cols = df_pivot.columns.tolist()\n",
    "\n",
    "# Separar en las diferentes categor√≠as\n",
    "energia_cols = sorted([c for c in cols if c.startswith('Energ√≠a KWh')], key=extraer_anio_mes)\n",
    "ingresos_energia_cols = sorted([c for c in cols if c.startswith('Ingresos Energ√≠a USD')], key=extraer_anio_mes)\n",
    "ingresos_renovables_cols = sorted([c for c in cols if c.startswith('Ingresos Renovables USD')], key=extraer_anio_mes)\n",
    "ingresos_potencia_cols = sorted([c for c in cols if c.startswith('Ingresos Potencia USD')], key=extraer_anio_mes)\n",
    "\n",
    "# AQU√ç EST√Å EL CAMBIO IMPORTANTE: Incluir Energ√≠a kWh primero\n",
    "cols_ordenadas = energia_cols + ingresos_energia_cols + ingresos_renovables_cols + ingresos_potencia_cols\n",
    "\n",
    "# Reordenar columnas\n",
    "df_pivot = df_pivot[cols_ordenadas]\n",
    "\n",
    "# Resetear √≠ndice\n",
    "df_final = df_pivot.reset_index()\n",
    "\n",
    "# Guardar resultado\n",
    "df_final.to_excel(\"./preprocess/serie_ingresos_cronologica.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c7cfd",
   "metadata": {},
   "source": [
    "# 4. Depuracion de serie de tiempo de energia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4e94664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado: Se han a√±adido las columnas de precio mon√≥mico con unidades USD/MWh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n",
      "C:\\Users\\daniel.canedo\\AppData\\Local\\Temp\\ipykernel_48132\\3388279339.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[precio_col] = np.where(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Leer el archivo Excel\n",
    "df = pd.read_excel(\"./preprocess/serie_ingresos_cronologica.xlsx\")\n",
    "\n",
    "# Lista de agentes a eliminar\n",
    "agentes_a_eliminar = [\n",
    "    \"TOTAL - CESSA\", \"TOTAL - CRE R.L.\", \"TOTAL CRE\", \"TOTAL - DELAPAZ\", \n",
    "    \"TOTAL - ELFEC\", \"TOTAL - ENDE\", \"TOTAL ENDE DELBENI S.A.M.\",\n",
    "    \"TOTAL - ENDE DEORURO S.A.\", \"TOTALES\", \"Tipo de cambio\",\n",
    "    \"TOTAL - SEPSA\", \"TOTAL - SETAR\"\n",
    "]\n",
    "\n",
    "# Filtrar y eliminar las filas no deseadas\n",
    "df = df[~df[\"CENTRAL\"].isin(agentes_a_eliminar)]\n",
    "\n",
    "# Convertir todas las columnas num√©ricas (remover comas y convertir a float)\n",
    "numeric_cols = df.columns.drop(['CENTRAL', 'GENERADOR', 'TECNOLOGIA'])\n",
    "for col in numeric_cols:\n",
    "    if df[col].dtype == object:\n",
    "        df[col] = df[col].str.replace(',', '', regex=False)\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Identificar periodos √∫nicos (ej: 012023, 022023, etc)\n",
    "periods = []\n",
    "for col in df.columns:\n",
    "    if col.startswith('Energ√≠a KWh') or col.startswith('Ingresos Energ√≠a USD') or col.startswith('Ingresos Renovables USD') or col.startswith('Ingresos Potencia USD'):\n",
    "        period = col.split(' ')[-1]\n",
    "        periods.append(period)\n",
    "\n",
    "# Calcular precio mon√≥mico para cada periodo con el nombre de columna corregido\n",
    "for period in periods:\n",
    "    energia_col = f'Energ√≠a KWh {period}'\n",
    "    ing_ener_col = f'Ingresos Energ√≠a USD {period}'\n",
    "    ing_ren_col = f'Ingresos Renovables USD {period}'\n",
    "    ing_pot_col = f'Ingresos Potencia USD {period}'\n",
    "    precio_col = f'Precio Mon√≥mico USD/MWh {period}'  # Nombre corregido\n",
    "    \n",
    "    # Verificar que existen las columnas necesarias\n",
    "    if all(col in df.columns for col in [energia_col, ing_ener_col, ing_ren_col, ing_pot_col]):\n",
    "        # Calcular suma de ingresos\n",
    "        total_ingresos = df[ing_ener_col] + df[ing_ren_col] + df[ing_pot_col]\n",
    "        \n",
    "        # Calcular precio mon√≥mico evitando divisi√≥n por cero\n",
    "        df[precio_col] = np.where(\n",
    "            df[energia_col] > 0,\n",
    "            (total_ingresos / df[energia_col]) * 1000,  # USD/MWh\n",
    "            np.nan\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Advertencia: Columnas incompletas para el per√≠odo {period}\")\n",
    "\n",
    "# Guardar el DataFrame con las nuevas columnas\n",
    "df.to_excel(\"./data/serie_ingresos.xlsx\", index=False)\n",
    "\n",
    "print(\"Proceso completado: Se han a√±adido las columnas de precio mon√≥mico con unidades USD/MWh\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
